{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Visual Analysis of Gun tweets and Gun stocks</center>\n",
    "<center> Lisa Phung  <br> <center>\n",
    "\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from pandas import Timestamp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweepy API grabbed tweets using certain keywords such as guns, 2nd Amendment, and firearms for a given amount of time. Each tweet and the time it was tweeted is written to a new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ckey = \"kLEVLIO4HHblzsmhooY7y0ezV\"\n",
    "csecret = \"MM3PAEN9Rjxu0Kgnil9eA37ET4cCcfaoTvMmmkShLYDLz3FOKn\"\n",
    "atoken = \"235327323-aPVX5Tl022C8a2pfSllVNHrsihKL4D9kXYUYyeWI\"\n",
    "asecret = \"dPaSPwBil04uhjtKynCkKaqnCgcTaucL74q3zAeAexVC0\"\n",
    "\n",
    "textList = []\n",
    "dateList = []\n",
    "class MyStreamListener(StreamListener):\n",
    "    def __init__(self, time_limit=60):\n",
    "        self.start_time = time.time()\n",
    "        self.limit = time_limit\n",
    "        self.saveFile = open('abcd.json', 'a')\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.filename = 'data' + '_' + time.strftime('%Y%m%d-%H%M%S') + '.csv'\n",
    "        # Create a new file with that filename\n",
    "        csvFile = open(self.filename, 'w', encoding='utf-8')\n",
    "\n",
    "        # Create a csv writer\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "\n",
    "        #Write a single row with the headers of the columns\n",
    "        csvWriter.writerow(['text','created_at'])\n",
    "\n",
    "\n",
    "    def on_data(self, data):\n",
    "        if (time.time() - self.start_time) < self.limit:\n",
    "            all_data = json.loads(data)\n",
    "            tweet = all_data[\"text\"]\n",
    "            username = all_data[\"user\"][\"screen_name\"]\n",
    "            date = all_data[\"created_at\"]\n",
    "            # Open the csv file created previously\n",
    "            csvFile = open(self.filename, 'a', encoding='utf-8')\n",
    "\n",
    "            # Create a csv writer\n",
    "            csvWriter = csv.writer(csvFile)\n",
    "\n",
    "            csvWriter.writerow([tweet, date])\n",
    "\n",
    "            # Close the csv file\n",
    "            csvFile.close()\n",
    "\n",
    "\n",
    "            #print((username, tweet))\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Time is up!\")\n",
    "            return False\n",
    "\n",
    "auth = OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "\n",
    "myStream = Stream(auth, listener=MyStreamListener(time_limit=10)) #Stream will stay open for 10 seconds (or whatever integer you pass)\n",
    "myStream.filter(track=['guns', '2ndAmendment', 'firearms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is the csv which was created using the tweepy api to stream tweets for certain keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_20171211-153014.csv\",encoding = \"ISO-8859-1\", names=['Tweet', 'Created At'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Stream Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "filenames = [\"data_20171211-153007.csv\",\n",
    "             \"data_20171212-153008.csv\", \"data_20171213-153003.csv\", \n",
    "             \"data_20171212-153206.csv\", \"data_20171211-153014.csv\"] # Fill in remaining files.\n",
    "\n",
    "\n",
    "#combines all the data into one csv\n",
    "header_saved = False\n",
    "with open('output.csv','w', encoding='ISO-8859-1') as fout:\n",
    "    for filename in filenames:\n",
    "        with open(filename, encoding='ISO-8859-1') as fin:\n",
    "            header = next(fin)\n",
    "            if not header_saved:\n",
    "                fout.write(header)\n",
    "                header_saved = True\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "#Combines data for just Monday\n",
    "filenames = [\"data_20171211-153007.csv\",\"data_20171211-153014.csv\"] # Fill in remaining files.\n",
    "\n",
    "header_saved = False\n",
    "with open('monday.csv','w', encoding='ISO-8859-1') as fout:\n",
    "    for filename in filenames:\n",
    "        with open(filename, encoding='ISO-8859-1') as fin:\n",
    "            header = next(fin)\n",
    "            if not header_saved:\n",
    "                fout.write(header)\n",
    "                header_saved = True\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "#Combines data for just Tuesday\n",
    "filenames1 = [\"data_20171212-153008.csv\",\"data_20171212-153206.csv\",] # Fill in remaining files.\n",
    "\n",
    "header_saved = False\n",
    "with open('tuesday.csv','w', encoding='ISO-8859-1') as fout:\n",
    "    for filename in filenames1:\n",
    "        with open(filename, encoding='ISO-8859-1') as fin:\n",
    "            header = next(fin)\n",
    "            if not header_saved:\n",
    "                fout.write(header)\n",
    "                header_saved = True\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "                \n",
    "#Combines data for just Wednesday                \n",
    "filenames2 = [\"data_20171213-153003.csv\"] # Fill in remaining files.\n",
    "\n",
    "header_saved = False\n",
    "with open('wednesday.csv','w', encoding='ISO-8859-1') as fout:\n",
    "    for filename in filenames2:\n",
    "        with open(filename, encoding='ISO-8859-1') as fin:\n",
    "            header = next(fin)\n",
    "            if not header_saved:\n",
    "                fout.write(header)\n",
    "                header_saved = True\n",
    "            for line in fin:\n",
    "                fout.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis using the tweets from the csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create dataframe object from csv file\n",
    "df = pd.read_csv('output.csv')\n",
    "#df1 = pd.read_csv('data_20171212-153311.csv')\n",
    "\n",
    "#create variable name for column that contains text of tweets\n",
    "text = df['text']\n",
    "sentimentlist = []\n",
    "\n",
    "\n",
    "\n",
    "#iterate through each tweet in the first column of csv\n",
    "for row in df['text']:\n",
    "    analysis = TextBlob(row)\n",
    "    \n",
    "    #add sentiment scores to a list\n",
    "    sentimentlist.append(analysis.sentiment.polarity)\n",
    "\n",
    "    #add a column in dataframe with sentiment scores\n",
    "df[\"Sentiment Score\"] = sentimentlist\n",
    "\n",
    "#make a new column that changes the time to integers\n",
    "df['dateInt'] = pd.to_datetime(df.created_at)\n",
    "df.sort_values(by='dateInt')\n",
    "\n",
    "#calculates moving average of Sentiment score\n",
    "df['Moving Average'] = df['Sentiment Score'].rolling(5).mean()\n",
    "\n",
    "#creates line graph over time of Sentiment Score\n",
    "df.plot('dateInt', 'Moving Average')\n",
    "# df.plot('dateInt', 'Sentiment Score')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in tweet and stock data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create dataframe object from csv file\n",
    "df = pd.read_csv('monday.csv')\n",
    "df1 = pd.read_csv('tuesday.csv')\n",
    "df2 = pd.read_csv('wednesday.csv')\n",
    "#df4 = pd.read_csv('output.csv')\n",
    "df3 = pd.read_csv(\"RGRdata.csv\",encoding = \"ISO-8859-1\", names=['someNum', 'close', 'high','low','open','volume','date'])\n",
    "df3.drop(df.head(8).index,inplace=True)\n",
    "df3 = df3[:-1]\n",
    "# print(MonHighRGR = df3.iloc[229:257, 'high'])\n",
    "# print(MonDateRGR = df3.iloc[229.257, 'date'])\n",
    "\n",
    "RGR = df3[['high', 'date']].copy()\n",
    "\n",
    "MonRGR = RGR.iloc[229:257]\n",
    "TuesRGR = RGR.iloc[476:505]\n",
    "WedRGR = RGR.iloc[766:794]\n",
    "\n",
    "\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "#create variable name for column that contains text of tweets\n",
    "# text = df['text']\n",
    "# text1 = df1['text']\n",
    "# text2 = df2['text']\n",
    "#text4 = df4['text']\n",
    "sentimentlist = []\n",
    "sentimentlist1 = []\n",
    "sentimentlist2 = []\n",
    "sentimentlist4 = []\n",
    "\n",
    "#create\n",
    "\n",
    "#iterate through each tweet in the first column of csv\n",
    "for row in df['text']:\n",
    "    analysis = TextBlob(row)\n",
    "    \n",
    "    #add sentiment scores to a list\n",
    "    sentimentlist.append(analysis.sentiment.polarity)\n",
    "for row in df1['text']:\n",
    "    analysis = TextBlob(row)\n",
    "    \n",
    "    #add sentiment scores to a list\n",
    "    sentimentlist1.append(analysis.sentiment.polarity)\n",
    "for row in df2['text']:\n",
    "    analysis = TextBlob(row)\n",
    "    \n",
    "     #add sentiment scores to a list\n",
    "    sentimentlist2.append(analysis.sentiment.polarity)\n",
    "    \n",
    "# for row in df4['text']:\n",
    "#     analysis = TextBlob(row)\n",
    "    \n",
    "#     #add sentiment scores to a list\n",
    "#     sentimentlist4.append(analysis.sentiment.polarity)\n",
    "\n",
    "\n",
    "    #add a column in dataframe with sentiment scores\n",
    "df[\"Sentiment Score\"] = sentimentlist\n",
    "df1[\"Sentiment Score\"] = sentimentlist1\n",
    "df2[\"Sentiment Score\"] = sentimentlist2\n",
    "#df4[\"Sentiment Score\"] = sentimentlist4\n",
    "\n",
    "# list_temp = []\n",
    "# for row in df4['created_at']:\n",
    "#     list_temp.append(Timestamp(row, tz = 'UTC').tz_convert('US/Eastern'))\n",
    "# df4['created_at'] = list_temp\n",
    "\n",
    "list_temp1 = []\n",
    "for row in df3['date']:\n",
    "    list_temp1.append(Timestamp(row, tz = 'EST').tz_convert('US/Eastern'))\n",
    "df3['date'] = list_temp1\n",
    "\n",
    "#make a new column that changes the time to integers\n",
    "df['dateInt'] = pd.to_datetime(df.created_at)\n",
    "df1['dateInt'] = pd.to_datetime(df1.created_at)\n",
    "df2['dateInt'] = pd.to_datetime(df2.created_at)\n",
    "#df4['date'] = pd.to_datetime(df4.created_at)\n",
    "df3['date'] = pd.to_datetime(df3.date)\n",
    "MonRGR['date'] = pd.to_datetime(MonRGR.date)\n",
    "TuesRGR['date'] = pd.to_datetime(TuesRGR.date)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#calculates moving average of Sentiment score\n",
    "df['Moving Average'] = df['Sentiment Score'].rolling(5).mean()\n",
    "df1['Moving Average'] = df1['Sentiment Score'].rolling(5).mean()\n",
    "df2['Moving Average'] = df2['Sentiment Score'].rolling(5).mean()\n",
    "#df4['Moving Average'] = df4['Sentiment Score'].rolling(5).mean()\n",
    "#creates line graph over time of Sentiment Score\n",
    "#df.plot('dateInt', ['Moving Average', '')\n",
    "#RGR.plot('dateInt', 'high')\n",
    "#df2.plot('dateInt', 'Moving Average')\n",
    "# df.plot('dateInt', 'Sentiment Score')\n",
    "\n",
    "#merge = df.append(MonRGR, ignore_index=True)\n",
    "#merge.to_csv('file_name.csv')\n",
    "\n",
    "\n",
    "\n",
    "#merged.to_csv('file_name.csv')\n",
    "\n",
    "# MonRGR.high = MonRGR.high.astype(float)\n",
    "# df3.high = df3.high.astype(float)\n",
    "# df3[229:256].set_index('date')['high'].plot()\n",
    "# df.plot('dateInt', 'Moving Average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Monday Tweets and Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "fig.set_size_inches(12, 4)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Monday Stock of Sturm, Ruger & Company, Inc')\n",
    "plt.ylabel('Stock')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.plot(df3[229:256].set_index('date')['high'])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Sentiment Scores of Tweets from 12/11/17')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.plot(df['dateInt'], df[\"Moving Average\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Tuesday Tweets and Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "fig.set_size_inches(12, 4)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Tuesday Stock of Sturm, Ruger & Company, Inc')\n",
    "plt.ylabel('Stock')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.plot(df3[476:505].set_index('date')['high'])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Sentiment Scores of Tweets from 12/12/17')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.plot(df1['dateInt'], df1[\"Moving Average\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Wednesday Tweets and Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "fig.set_size_inches(12, 4)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Wednesday Stock of Sturm, Ruger & Company, Inc')\n",
    "plt.ylabel('Stock')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.plot(df3[766:794].set_index('date')['high'])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Sentiment Scores of Tweets from 12/13/17')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.plot(df2['dateInt'], df2[\"Moving Average\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
